  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- coding: utf-8; mode: latex -*- %%
  %
%%%%%                         CHAPTER
 %%%
  %

% $Id: 1020-lorem-ipsum.tex,v 1.2 2009/06/19 15:51:46 david Exp $
% $Log: 1020-lorem-ipsum.tex,v $
% Revision 1.2  2009/06/19 15:51:46
% *** empty log message ***
%
% Revision 1.1  2007/11/23 09:52:39
% *** empty log message ***
%
%

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                           HEAD MATTER
 %%%
  %

\chapter{Introduction}
%\addcontentsline{lof}{chapter}{\thechapter\quad Lorem Ipsum}
%\addcontentsline{lot}{chapter}{\thechapter\quad Lorem Ipsum}
\label{ch:intro}

\begin{quotation}
"Your system can fail no matter how well you thought you tested it... what users will not tolerate is losing their data".
{\small\it -- ~\footnote{Lehene C. HStack, http://hstack.org/why-were-using-hbase-part-2} }
\end{quotation}



  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                        FIRST SECTION
 %%%
  %
  %

\section{Overview}
The idea of Geo-replication and consistency in distributed systems is not a new concept~\cite{Ferreira:98} ~\cite{Kubiatowicz:2000}. Since we have applications with data distributed across geographically distant locations, it is necessary to improve how applications and users access that information to it is served in a fast and appropriate fashion. In general, there are two components in Geo-replication, at the first lower-level  tier is the hardware components and in a higher layer is the software, in which we actually focus the thesis here presented.

Nowadays there are not still fully robust tools that are able to simulate and test real world scenarios for issues such as replication, fault-tolerance and consistency in distributed systems. There have been some improvements in that field, and today the Yahoo Cloud Service Benchmarking~\cite{YCSB:2010} is a well-known platform benchmark to test different kinds of distributed data stores and their performance against different types of workloads.

There is a wide variety and at the same time similar type of consistency models that have been proposed so far in distributed systems, whether they are in the form of strong, eventual or weak properties, regarding the consistency enforcement for data replication. Each of them claims to be suitable for different types of applications, providing also different data semantics. Although, something they have in common is their trade-offs between one of the three variables defined in one of the most currently well-known paradigm of distributed systems, the CAP theorem~\cite{Brewer:2002}. In some cases, depending of what an application tolerates or caters best for, is more important to have a very consistent systems, highly-available, or very tolerant to partitions in the networks, but as it is stated by Brewer, not the three of them at once would be possible.

% --- This and the above could well go in a more extended % version to the Related work version.
%
% Bayou and Dynamo adopted eventual (optimistic at local, lazily replicated at remote sites)
%
% Azure uses strong consistency

For achieving low-latency one can split the operations in two or more categories in order of importance, therefore having some of them replicated with stronger consistency guarantees or faster with just eventual consistency~\cite{Li:2012}. This is a good approach for some applications, and this thesis is also inspired in that approach because it creates a more flexible scenario, which allows systems to adapt to the needs over time and data if required.

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                      SECOND SECTION
 %%%
  %

\section{Problem Statement}
It is well know that the definition of Replication involves several basic aspects. Firstly, replication not only copies data from one location, but also synchronizes a set of replicas so that the modifications are also reflected to the rest.

If in a system synchronization there is a the burden for latency, then it is because performance may matter above consistency. In~\cite{Lloyd:2011}, it is presented the idea of Causal Consistency with a set of properties called ALPS,\footnote{Availability, low Latency, Partition-tolerance, and high-scalability} so in theory one does not need to sacrifice consistency significantly for performance. Although there may be conflicts, one can resolve those, in a higher level of abstraction with approaches such as latest writer wins, as it is also noted.

On the other hand, systems as PNUTS from Yahoo~\cite{Cooper:2008} introduced a novel approach for consistency on a per-record basis, therefore providing low latency during heavy replication operations for large web scale applications. It is realized how eventual consistency is not enough in the case of social and sharing networks, as having stale replicas can be a problem concerning users' privacy because of data consistency misbehavior.

Therefore, consistency is a major case of study and source of several issues in geo-located and distributed systems, particularly high-performing cloud data stores. Those systems require flexible, adaptable and a more dynamic way of enforcing data consistency. Based on that, it is important to provide smart semantics that best serve applications, avoiding overloading both network and distributed systems during large periods of disconnection or partitions in the network. There is well-known and previous work in that regard~\cite{Kraska:2009}~\cite{chihoub:2013}, which has also partially inspired the work now presented.

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extended motivation and Roadmap}
In Cloud Computing replication of data in distributed systems is becoming a major challenge with large amounts of information that require consistency and high availability as well as resilience to failures. Nowadays there are several solutions to the problem, none of them applicable in all cases, as they are determined by the type of system built and its final goals. As the CAP theorem states~\cite{Brewer:2002}, one can not ensure the three properties of a distributed system all at once, therefore having to choose two out of three for each application between consistency, availability and tolerate or not partitions in the network. Several relaxed consistency models have also been devised in that area regarding innovative and flexible models of consistency, requiring redesign of application data types~\cite{Saphiro:2011} or via middle-ware intercepting and reflecting APIs~\cite{Vfc3:2012}.

In this thesis work we explore what are the main trends and scenarios of non-relational cloud-based tabular data stores. The main reason is to understand how to make those systems scalable, when and why is availability of data always necessary, and how its level of consistency can determine the application outcomes. For that, we first dive into the fundamentals of several well-known existing consistency models in the area of distributed systems while taking particular attention to the concept of eventual and strong consistency. For that, later, a \emph{quality-of-data} framework or model is defined, which is mainly characterized by the levels of consistency one can provide in replica nodes to end users and therefore differentiate between updates that are going to be replicated. That is taking into account, whether is during off-peak or high-load network usage scenarios. 

Given this is our main focus of attention, and that many models exist in the area, we look into retrospective to those first, and realize as we will explain that while they have been blended and tuned in different forms, none of them actually reinvents the wheel in technical terms. Following up, a special interest resides into leveraging the model for catering of several users and applications, that can benefit from our approach in the concept of saving bandwidth and reducing latency, during periods of higher activity between data centers or disconnections.

First, we are enhancing the eventual consistency model for inter-site replication in HBase by using an adaptive consistency model that can provide different levels of consistency depending of the Service Level Objective or Agreement required. The idea can be somehow similar to the "pluggable replication framework" proposed within the HBase community~\cite{JIRA-1}, so our work has a two-fold purpose. First, present this thesis work and secondly contributing to the open source community of HBase by presenting our proposal, with its integration into the core architecture of the system, therefore avoiding another middle-ware layer on top of it. That also simplifies its usage to programmers and HBase developers or administrators.

This in order to achieve giving a better understanding of what other replication guarantees can such a system offer, its value to users, and how a flexible consistency model can be applied to the core of a NoSQL distributed data store. This is valuable to users and applications that require differentiating between data semantics for replication. 

The research is mainly targeting the replication mechanisms HBase currently does not provide, by assessing how one can extend those already in place and provided within its codebase. It is very interesting to see how there are several discussions opened in this same direction on their community, some of them actually proposing selective replication of updates to peer clusters. 

So at the client level one user would be able to see something or not, depending of the cluster it has access to or requesting reads from. That is far more efficient in terms of resource consumption and bandwidth usage in geo-located data centers and there is a rising interest in the topic for that very same reason, cost savings.



  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                         ANOTHER SECTION
 %%%
  %
\section{Research Proposal}
Distributed HBase deployments have one or more master nodes (HMaster), which coordinate the entire cluster, and many slave nodes (RegionServer), which handle the actual data storage.  Therefore a write-ahead log (WAL) is used for data retention in replication for high availability. Currently the architecture of Apache HBase is designed to provide eventual consistency, updates are replicated asynchronously between data centers. Thus, we can not predict accurately enough or decide when replication takes place or ensure a given level of quality of data for delivery to a remote replica.

The main goal of this work is to incorporate a more flexible, fine-grained and adaptive consistency model at the HBase core architecture level. That can be a feature part of HBase to have bandwidth savings on inter-site datacenter replication, to help avoiding peak transfer loads on time of high update rate, while still enforcing some \emph{quality-of-data} to users regarding recency (or number of pending updates and value divergence between replicas) so enhancing the eventual consistency guarantees.

HBase is a relevant example of a large scale cloud data store. This work takes a closer look at its architecture and introduces levels of consistency with a quality of data module (HBase-QoD). The proposal is having the required flexibility for serving data to clients, while keeping control of geo-replicated and distributed databases. This can optimize usage of resources while still providing an enhanced experience to the end user. Application behavior is more efficient but involves a slightly different shift into the consistency paradigm as seen in \cite{Cooper:2008}. This is realized by modifying existing eventual consistency mechanisms of HBase with an innovative approach, which allows handling replication of updates on-demand and on a per-request or user basis.


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                          LAST SECTION
 %%%
  %

\section{Contributions}
The contribution here presented is an accurate understanding of what real advantages can be achieved using that model, which is evaluated later in the section with the same name.  From the architectural point of view, the model can be complemented with the corresponding replication guarantees on top of it that can be among others, causal or causal++, but none of them offers bounds on staleness of data as we aim to. This is valuable to business users for knowing and learning about how to best serve requests while making datacenters more cost and energy-efficient optimizing existing resources. Therefore, finally, it will be realized how the advantages of using flexible mechanisms, when it comes to replication at global scale, can overcome those that impose strict guarantees of data consistency for highly-synchronized applications.

%Our result should be positive in terms of both, performance versus quality of the service.

Latency can be reduced by imposing some constraints (time bounds or others regarding number of pending updates and value divergence) on the replication mechanisms of HBase providing a two-fold advantage: i) ensure that a best-effort scenario does not overload a network with thousands of updates that might be too small (can be batched too if desired) and also and more importantly, ii) updates can be prioritized so that systems are still able to achieve an agreed quality of service with the user in resource constrained environments.


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                         ANOTHER SECTION
 %%%
  %
%\section{Thesis objectives and expected results}

The main contributions of the thesis are based in the analysis of the existing generic geo-replication mechanisms in the area of distributed systems with a special focus for those into HBase. Besides, a model that provides tunable consistency it is introduced and applied to the cloud data store with the following improvements:
\begin{itemize}
\item Replication mechanisms that control flow of updates during replication.
\item Quality of Data engine plugs into HBase so enhancing eventual consistency adding consistency guarantees based on data-semantics.
\item Results obtained are evaluated for gains in performance and/or bandwidth savings by using the HBase-QoD implementation.
\end{itemize}

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                         ANOTHER SECTION
 %%%
  %
\section{Publications}

The work presented in this thesis is partially described in the following peer-reviewed publications:
\begin{itemize}
\item  \'{A}lvaro Garc\'{i}a Recuero, S\'{e}rgio Esteves and Lu\'{i}s Veiga. Quality-of-Data for Consistency Levels in Geo-replicated Cloud Data Stores. In {\bf
     IEEE CloudCom 2013}, Bristol, UK, Dec. 2013, IEEE (6-page short paper).


\item \'{A}lvaro Garc\'{i}a Recuero, Lu\'{i}s Veiga. Quality-of-Data Consistency Levels in HBase for GeoReplication. In 11th Usenix Conference on File and Storage Technologies, {\bf (FAST 2013)}, San Jose, CA, USA, Feb. 2013, Usenix (2-page Work-in-Progress report and Poster).
\end{itemize}



  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
%%%%%                          FINAL SECTION
%%%%%
 %%%
  %

\section{Structure of the thesis}

The remaining of this thesis is organized in a number chapters.
%
%
In Chapter~\ref{ch:relatedwork}, following, we study and analyze the relevant related work in the literature on the thesis' topics. In Chapter~\ref{ch:architecture}, we describe the main insights of our proposed solution, highlighting relevant aspects regarding architecture, algorithms, protocols and data structures. Chapter~\ref{ch:implemenation} describe the most important and specific lower-level details of the solution implementation and deployment. In Chapter~\ref{ch:evaluation}, we evaluate the performance of our solution resorting to two benchmarks found in the literature. Chapter~\ref{ch:conclusion} closes this document with some conclusions and future work.
%
At the beginning of each major chapter we outline its structure, and after describing it, we summarize the contents and topics presented.
%
%We have a list of figures and appendix for describing the number of items we reference during the text.

  %
 %%%
%%%%%                        THE END
  %
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "tese"
%%% End:
